{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis\n",
    "\n",
    "We're able to crawl for headlines from various collections but I don't yet know how to see which publishers are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fundus\n",
      "  Downloading fundus-0.5.0-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: python-dateutil<3,>=2.8 in /opt/anaconda3/envs/erdos_spring_2025/lib/python3.12/site-packages (from fundus) (2.9.0.post0)\n",
      "Requirement already satisfied: lxml<6,>=4.9 in /opt/anaconda3/envs/erdos_spring_2025/lib/python3.12/site-packages (from fundus) (5.3.0)\n",
      "Collecting more-itertools<10,>=9.1 (from fundus)\n",
      "  Downloading more_itertools-9.1.0-py3-none-any.whl.metadata (32 kB)\n",
      "Collecting cssselect<2,>=1.1 (from fundus)\n",
      "  Downloading cssselect-1.2.0-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting feedparser<7,>=6.0 (from fundus)\n",
      "  Downloading feedparser-6.0.11-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting colorama<1,>=0.4 (from fundus)\n",
      "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.6 in /opt/anaconda3/envs/erdos_spring_2025/lib/python3.12/site-packages (from fundus) (4.12.2)\n",
      "Collecting langdetect<2,>=1.0 (from fundus)\n",
      "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting validators<1,>=0.24 (from fundus)\n",
      "  Downloading validators-0.34.0-py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: requests<3,>=2.28 in /opt/anaconda3/envs/erdos_spring_2025/lib/python3.12/site-packages (from fundus) (2.32.3)\n",
      "Requirement already satisfied: tqdm<5,>=4.66 in /opt/anaconda3/envs/erdos_spring_2025/lib/python3.12/site-packages (from fundus) (4.67.1)\n",
      "Collecting fastwarc<1,>=0.14 (from fundus)\n",
      "  Downloading FastWARC-0.15.1-cp312-cp312-macosx_12_0_arm64.whl.metadata (3.2 kB)\n",
      "Collecting chardet<6,>=5.2 (from fundus)\n",
      "  Downloading chardet-5.2.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting dill<1,>=0.3 (from fundus)\n",
      "  Downloading dill-0.3.9-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting dict2xml<2,>=1.7.6 (from fundus)\n",
      "  Downloading dict2xml-1.7.6-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting xmltodict<1,>=0.13.0 (from fundus)\n",
      "  Downloading xmltodict-0.14.2-py2.py3-none-any.whl.metadata (8.0 kB)\n",
      "Requirement already satisfied: brotli in /opt/anaconda3/envs/erdos_spring_2025/lib/python3.12/site-packages (from fastwarc<1,>=0.14->fundus) (1.1.0)\n",
      "Collecting click (from fastwarc<1,>=0.14->fundus)\n",
      "  Downloading click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting sgmllib3k (from feedparser<7,>=6.0->fundus)\n",
      "  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: six in /opt/anaconda3/envs/erdos_spring_2025/lib/python3.12/site-packages (from langdetect<2,>=1.0->fundus) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/anaconda3/envs/erdos_spring_2025/lib/python3.12/site-packages (from requests<3,>=2.28->fundus) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/erdos_spring_2025/lib/python3.12/site-packages (from requests<3,>=2.28->fundus) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/erdos_spring_2025/lib/python3.12/site-packages (from requests<3,>=2.28->fundus) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/erdos_spring_2025/lib/python3.12/site-packages (from requests<3,>=2.28->fundus) (2024.12.14)\n",
      "Downloading fundus-0.5.0-py3-none-any.whl (192 kB)\n",
      "Downloading chardet-5.2.0-py3-none-any.whl (199 kB)\n",
      "Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "Downloading cssselect-1.2.0-py2.py3-none-any.whl (18 kB)\n",
      "Downloading dict2xml-1.7.6-py3-none-any.whl (8.0 kB)\n",
      "Downloading dill-0.3.9-py3-none-any.whl (119 kB)\n",
      "Downloading FastWARC-0.15.1-cp312-cp312-macosx_12_0_arm64.whl (438 kB)\n",
      "Downloading feedparser-6.0.11-py3-none-any.whl (81 kB)\n",
      "Downloading more_itertools-9.1.0-py3-none-any.whl (54 kB)\n",
      "Downloading validators-0.34.0-py3-none-any.whl (43 kB)\n",
      "Downloading xmltodict-0.14.2-py2.py3-none-any.whl (10.0 kB)\n",
      "Downloading click-8.1.8-py3-none-any.whl (98 kB)\n",
      "Building wheels for collected packages: langdetect, sgmllib3k\n",
      "  Building wheel for langdetect (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993284 sha256=37cbc6d64782fad4ef4e5362cb4303e373bdddb49bf19bdc4f4d3f991469958c\n",
      "  Stored in directory: /Users/samauyeung/Library/Caches/pip/wheels/c1/67/88/e844b5b022812e15a52e4eaa38a1e709e99f06f6639d7e3ba7\n",
      "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6089 sha256=7af6599d61fb2c1ac39f36026bfd78fcdd15b1b9c54aba955a9ddcb325a5f3b8\n",
      "  Stored in directory: /Users/samauyeung/Library/Caches/pip/wheels/03/f5/1a/23761066dac1d0e8e683e5fdb27e12de53209d05a4a37e6246\n",
      "Successfully built langdetect sgmllib3k\n",
      "Installing collected packages: sgmllib3k, xmltodict, validators, more-itertools, langdetect, feedparser, dill, dict2xml, cssselect, colorama, click, chardet, fastwarc, fundus\n",
      "Successfully installed chardet-5.2.0 click-8.1.8 colorama-0.4.6 cssselect-1.2.0 dict2xml-1.7.6 dill-0.3.9 fastwarc-0.15.1 feedparser-6.0.11 fundus-0.5.0 langdetect-1.0.9 more-itertools-9.1.0 sgmllib3k-1.0.0 validators-0.34.0 xmltodict-0.14.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install fundus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting flair\n",
      "  Downloading flair-0.15.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting boto3>=1.20.27 (from flair)\n",
      "  Downloading boto3-1.37.5-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting conllu<5.0.0,>=4.0 (from flair)\n",
      "  Downloading conllu-4.5.3-py2.py3-none-any.whl.metadata (19 kB)\n",
      "Collecting deprecated>=1.2.13 (from flair)\n",
      "  Downloading Deprecated-1.2.18-py2.py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting ftfy>=6.1.0 (from flair)\n",
      "  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting gdown>=4.4.0 (from flair)\n",
      "  Downloading gdown-5.2.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting huggingface-hub>=0.10.0 (from flair)\n",
      "  Downloading huggingface_hub-0.29.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: langdetect>=1.0.9 in /opt/anaconda3/envs/erdos_spring_2025/lib/python3.12/site-packages (from flair) (1.0.9)\n",
      "Requirement already satisfied: lxml>=4.8.0 in /opt/anaconda3/envs/erdos_spring_2025/lib/python3.12/site-packages (from flair) (5.3.0)\n",
      "Requirement already satisfied: matplotlib>=2.2.3 in /opt/anaconda3/envs/erdos_spring_2025/lib/python3.12/site-packages (from flair) (3.10.0)\n",
      "Requirement already satisfied: more-itertools>=8.13.0 in /opt/anaconda3/envs/erdos_spring_2025/lib/python3.12/site-packages (from flair) (9.1.0)\n",
      "Collecting mpld3>=0.3 (from flair)\n",
      "  Downloading mpld3-0.5.10-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting pptree>=3.1 (from flair)\n",
      "  Downloading pptree-3.1.tar.gz (3.0 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/envs/erdos_spring_2025/lib/python3.12/site-packages (from flair) (2.9.0.post0)\n",
      "Collecting pytorch-revgrad>=0.2.0 (from flair)\n",
      "  Downloading pytorch_revgrad-0.2.0-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting regex>=2022.1.18 (from flair)\n",
      "  Downloading regex-2024.11.6-cp312-cp312-macosx_11_0_arm64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in /opt/anaconda3/envs/erdos_spring_2025/lib/python3.12/site-packages (from flair) (1.6.1)\n",
      "Collecting segtok>=1.5.11 (from flair)\n",
      "  Downloading segtok-1.5.11-py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting sqlitedict>=2.0.0 (from flair)\n",
      "  Downloading sqlitedict-2.1.0.tar.gz (21 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting tabulate>=0.8.10 (from flair)\n",
      "  Downloading tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
      "Collecting torch>=1.13.1 (from flair)\n",
      "  Downloading torch-2.6.0-cp312-none-macosx_11_0_arm64.whl.metadata (28 kB)\n",
      "Requirement already satisfied: tqdm>=4.63.0 in /opt/anaconda3/envs/erdos_spring_2025/lib/python3.12/site-packages (from flair) (4.67.1)\n",
      "Collecting transformer-smaller-training-vocab>=0.2.3 (from flair)\n",
      "  Downloading transformer_smaller_training_vocab-0.4.0-py3-none-any.whl.metadata (8.1 kB)\n",
      "Collecting transformers<5.0.0,>=4.25.0 (from transformers[sentencepiece]<5.0.0,>=4.25.0->flair)\n",
      "  Downloading transformers-4.49.0-py3-none-any.whl.metadata (44 kB)\n",
      "Collecting wikipedia-api>=0.5.7 (from flair)\n",
      "  Downloading wikipedia_api-0.8.1.tar.gz (19 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting bioc<3.0.0,>=2.0.0 (from flair)\n",
      "  Downloading bioc-2.1-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting jsonlines>=1.2.0 (from bioc<3.0.0,>=2.0.0->flair)\n",
      "  Downloading jsonlines-4.0.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting intervaltree (from bioc<3.0.0,>=2.0.0->flair)\n",
      "  Downloading intervaltree-3.1.0.tar.gz (32 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting docopt (from bioc<3.0.0,>=2.0.0->flair)\n",
      "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting botocore<1.38.0,>=1.37.5 (from boto3>=1.20.27->flair)\n",
      "  Downloading botocore-1.37.5-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting jmespath<2.0.0,>=0.7.1 (from boto3>=1.20.27->flair)\n",
      "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting s3transfer<0.12.0,>=0.11.0 (from boto3>=1.20.27->flair)\n",
      "  Downloading s3transfer-0.11.3-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /opt/anaconda3/envs/erdos_spring_2025/lib/python3.12/site-packages (from deprecated>=1.2.13->flair) (1.17.2)\n",
      "Requirement already satisfied: wcwidth in /opt/anaconda3/envs/erdos_spring_2025/lib/python3.12/site-packages (from ftfy>=6.1.0->flair) (0.2.13)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/anaconda3/envs/erdos_spring_2025/lib/python3.12/site-packages (from gdown>=4.4.0->flair) (4.12.3)\n",
      "Collecting filelock (from gdown>=4.4.0->flair)\n",
      "  Downloading filelock-3.17.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: requests[socks] in /opt/anaconda3/envs/erdos_spring_2025/lib/python3.12/site-packages (from gdown>=4.4.0->flair) (2.32.3)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub>=0.10.0->flair)\n",
      "  Downloading fsspec-2025.2.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/anaconda3/envs/erdos_spring_2025/lib/python3.12/site-packages (from huggingface-hub>=0.10.0->flair) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/envs/erdos_spring_2025/lib/python3.12/site-packages (from huggingface-hub>=0.10.0->flair) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda3/envs/erdos_spring_2025/lib/python3.12/site-packages (from huggingface-hub>=0.10.0->flair) (4.12.2)\n",
      "Requirement already satisfied: six in /opt/anaconda3/envs/erdos_spring_2025/lib/python3.12/site-packages (from langdetect>=1.0.9->flair) (1.17.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/anaconda3/envs/erdos_spring_2025/lib/python3.12/site-packages (from matplotlib>=2.2.3->flair) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/envs/erdos_spring_2025/lib/python3.12/site-packages (from matplotlib>=2.2.3->flair) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/anaconda3/envs/erdos_spring_2025/lib/python3.12/site-packages (from matplotlib>=2.2.3->flair) (4.55.4)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/anaconda3/envs/erdos_spring_2025/lib/python3.12/site-packages (from matplotlib>=2.2.3->flair) (1.4.8)\n",
      "Requirement already satisfied: numpy>=1.23 in /opt/anaconda3/envs/erdos_spring_2025/lib/python3.12/site-packages (from matplotlib>=2.2.3->flair) (2.0.2)\n",
      "Requirement already satisfied: pillow>=8 in /opt/anaconda3/envs/erdos_spring_2025/lib/python3.12/site-packages (from matplotlib>=2.2.3->flair) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/anaconda3/envs/erdos_spring_2025/lib/python3.12/site-packages (from matplotlib>=2.2.3->flair) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/envs/erdos_spring_2025/lib/python3.12/site-packages (from mpld3>=0.3->flair) (3.1.5)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /opt/anaconda3/envs/erdos_spring_2025/lib/python3.12/site-packages (from scikit-learn>=1.0.2->flair) (1.15.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/anaconda3/envs/erdos_spring_2025/lib/python3.12/site-packages (from scikit-learn>=1.0.2->flair) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/anaconda3/envs/erdos_spring_2025/lib/python3.12/site-packages (from scikit-learn>=1.0.2->flair) (3.5.0)\n",
      "Collecting networkx (from torch>=1.13.1->flair)\n",
      "  Downloading networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/envs/erdos_spring_2025/lib/python3.12/site-packages (from torch>=1.13.1->flair) (75.8.0)\n",
      "Collecting sympy==1.13.1 (from torch>=1.13.1->flair)\n",
      "  Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch>=1.13.1->flair)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting numpy>=1.23 (from matplotlib>=2.2.3->flair)\n",
      "  Using cached numpy-1.26.4-cp312-cp312-macosx_11_0_arm64.whl.metadata (61 kB)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers<5.0.0,>=4.25.0->transformers[sentencepiece]<5.0.0,>=4.25.0->flair)\n",
      "  Downloading tokenizers-0.21.0-cp39-abi3-macosx_11_0_arm64.whl.metadata (6.7 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers<5.0.0,>=4.25.0->transformers[sentencepiece]<5.0.0,>=4.25.0->flair)\n",
      "  Downloading safetensors-0.5.3-cp38-abi3-macosx_11_0_arm64.whl.metadata (3.8 kB)\n",
      "Collecting sentencepiece!=0.1.92,>=0.1.91 (from transformers[sentencepiece]<5.0.0,>=4.25.0->flair)\n",
      "  Downloading sentencepiece-0.2.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (7.7 kB)\n",
      "Requirement already satisfied: protobuf in /opt/anaconda3/envs/erdos_spring_2025/lib/python3.12/site-packages (from transformers[sentencepiece]<5.0.0,>=4.25.0->flair) (5.29.3)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /opt/anaconda3/envs/erdos_spring_2025/lib/python3.12/site-packages (from botocore<1.38.0,>=1.37.5->boto3>=1.20.27->flair) (2.3.0)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /opt/anaconda3/envs/erdos_spring_2025/lib/python3.12/site-packages (from jsonlines>=1.2.0->bioc<3.0.0,>=2.0.0->flair) (24.3.0)\n",
      "Collecting accelerate>=0.26.0 (from transformers[sentencepiece,torch]<5.0,>=4.1->transformer-smaller-training-vocab>=0.2.3->flair)\n",
      "  Downloading accelerate-1.4.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/anaconda3/envs/erdos_spring_2025/lib/python3.12/site-packages (from beautifulsoup4->gdown>=4.4.0->flair) (2.5)\n",
      "Collecting sortedcontainers<3.0,>=2.0 (from intervaltree->bioc<3.0.0,>=2.0.0->flair)\n",
      "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/envs/erdos_spring_2025/lib/python3.12/site-packages (from jinja2->mpld3>=0.3->flair) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/anaconda3/envs/erdos_spring_2025/lib/python3.12/site-packages (from requests[socks]->gdown>=4.4.0->flair) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/erdos_spring_2025/lib/python3.12/site-packages (from requests[socks]->gdown>=4.4.0->flair) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/erdos_spring_2025/lib/python3.12/site-packages (from requests[socks]->gdown>=4.4.0->flair) (2024.12.14)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/anaconda3/envs/erdos_spring_2025/lib/python3.12/site-packages (from requests[socks]->gdown>=4.4.0->flair) (1.7.1)\n",
      "Requirement already satisfied: psutil in /opt/anaconda3/envs/erdos_spring_2025/lib/python3.12/site-packages (from accelerate>=0.26.0->transformers[sentencepiece,torch]<5.0,>=4.1->transformer-smaller-training-vocab>=0.2.3->flair) (6.1.1)\n",
      "Downloading flair-0.15.1-py3-none-any.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading bioc-2.1-py3-none-any.whl (33 kB)\n",
      "Downloading boto3-1.37.5-py3-none-any.whl (139 kB)\n",
      "Downloading conllu-4.5.3-py2.py3-none-any.whl (16 kB)\n",
      "Downloading Deprecated-1.2.18-py2.py3-none-any.whl (10.0 kB)\n",
      "Downloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n",
      "Downloading gdown-5.2.0-py3-none-any.whl (18 kB)\n",
      "Downloading huggingface_hub-0.29.1-py3-none-any.whl (468 kB)\n",
      "Downloading mpld3-0.5.10-py3-none-any.whl (202 kB)\n",
      "Downloading pytorch_revgrad-0.2.0-py3-none-any.whl (4.6 kB)\n",
      "Downloading regex-2024.11.6-cp312-cp312-macosx_11_0_arm64.whl (284 kB)\n",
      "Downloading segtok-1.5.11-py3-none-any.whl (24 kB)\n",
      "Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Downloading torch-2.6.0-cp312-none-macosx_11_0_arm64.whl (66.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.5/66.5 MB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading transformer_smaller_training_vocab-0.4.0-py3-none-any.whl (14 kB)\n",
      "Downloading transformers-4.49.0-py3-none-any.whl (10.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading botocore-1.37.5-py3-none-any.whl (13.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.4/13.4 MB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2025.2.0-py3-none-any.whl (184 kB)\n",
      "Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Downloading jsonlines-4.0.0-py3-none-any.whl (8.7 kB)\n",
      "Downloading numpy-1.26.4-cp312-cp312-macosx_11_0_arm64.whl (13.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.7/13.7 MB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading s3transfer-0.11.3-py3-none-any.whl (84 kB)\n",
      "Downloading safetensors-0.5.3-cp38-abi3-macosx_11_0_arm64.whl (418 kB)\n",
      "Downloading sentencepiece-0.2.0-cp312-cp312-macosx_11_0_arm64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.21.0-cp39-abi3-macosx_11_0_arm64.whl (2.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading filelock-3.17.0-py3-none-any.whl (16 kB)\n",
      "Downloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading accelerate-1.4.0-py3-none-any.whl (342 kB)\n",
      "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
      "Building wheels for collected packages: pptree, sqlitedict, wikipedia-api, docopt, intervaltree\n",
      "  Building wheel for pptree (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pptree: filename=pptree-3.1-py3-none-any.whl size=4638 sha256=cbb295b548eb198cc75821fed101d2fa07c469d7fed9f8704fc5ad37df9143fa\n",
      "  Stored in directory: /Users/samauyeung/Library/Caches/pip/wheels/b0/2d/de/37058114a8f07cfec75747cb46b864bc5c71b0e9e0e4cd0acd\n",
      "  Building wheel for sqlitedict (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sqlitedict: filename=sqlitedict-2.1.0-py3-none-any.whl size=16928 sha256=6e708ae7c56bae9eb111d35d80e1f6ea6e9e0120d711b4ebab6103a900d038d1\n",
      "  Stored in directory: /Users/samauyeung/Library/Caches/pip/wheels/7a/6f/21/fc016aef45ffcabe27129a2252f061387cbf278d2086225a64\n",
      "  Building wheel for wikipedia-api (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for wikipedia-api: filename=Wikipedia_API-0.8.1-py3-none-any.whl size=15446 sha256=8feb106999174cc5035097a882dcb7037a301b529df1c50338a2b643a6df41f5\n",
      "  Stored in directory: /Users/samauyeung/Library/Caches/pip/wheels/33/3c/79/b36253689d838af4a0539782853ac3cc38a83a6591ad570dde\n",
      "  Building wheel for docopt (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13749 sha256=ac4f7297052b87651b5b23bbdcf34bf7b940cadc3837bee445293c44b32d2133\n",
      "  Stored in directory: /Users/samauyeung/Library/Caches/pip/wheels/1a/bf/a1/4cee4f7678c68c5875ca89eaccf460593539805c3906722228\n",
      "  Building wheel for intervaltree (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for intervaltree: filename=intervaltree-3.1.0-py2.py3-none-any.whl size=26160 sha256=4ddcf9e9a6959a37bc0e7c68fe4fb012420b862893011efe4d688c754f2c900b\n",
      "  Stored in directory: /Users/samauyeung/Library/Caches/pip/wheels/65/c3/c3/238bf93c243597857edd94ddb0577faa74a8e16e9585896e83\n",
      "Successfully built pptree sqlitedict wikipedia-api docopt intervaltree\n",
      "Installing collected packages: sqlitedict, sortedcontainers, sentencepiece, pptree, mpmath, docopt, tabulate, sympy, safetensors, regex, numpy, networkx, jsonlines, jmespath, intervaltree, ftfy, fsspec, filelock, deprecated, conllu, wikipedia-api, torch, segtok, huggingface-hub, botocore, bioc, tokenizers, s3transfer, pytorch-revgrad, gdown, accelerate, transformers, mpld3, boto3, transformer-smaller-training-vocab, flair\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.0.2\n",
      "    Uninstalling numpy-2.0.2:\n",
      "      Successfully uninstalled numpy-2.0.2\n",
      "Successfully installed accelerate-1.4.0 bioc-2.1 boto3-1.37.5 botocore-1.37.5 conllu-4.5.3 deprecated-1.2.18 docopt-0.6.2 filelock-3.17.0 flair-0.15.1 fsspec-2025.2.0 ftfy-6.3.1 gdown-5.2.0 huggingface-hub-0.29.1 intervaltree-3.1.0 jmespath-1.0.1 jsonlines-4.0.0 mpld3-0.5.10 mpmath-1.3.0 networkx-3.4.2 numpy-1.26.4 pptree-3.1 pytorch-revgrad-0.2.0 regex-2024.11.6 s3transfer-0.11.3 safetensors-0.5.3 segtok-1.5.11 sentencepiece-0.2.0 sortedcontainers-2.4.0 sqlitedict-2.1.0 sympy-1.13.1 tabulate-0.9.0 tokenizers-0.21.0 torch-2.6.0 transformer-smaller-training-vocab-0.4.0 transformers-4.49.0 wikipedia-api-0.8.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install flair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fundus import PublisherCollection, Crawler, NewsMap\n",
    "from flair.data import Sentence\n",
    "from flair.models import TextClassifier\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fundus-Article including 1 image(s):\n",
      "- Title: \"Trump Donors Try to Buy Pittsburgh Mayor’s Race\"\n",
      "- Text:  \"Now that Republicans have won control of government in Washington, they’re\n",
      "          shifting their sights to a progressive enclave in Pennsylvania. [...]\"\n",
      "- URL:    https://theintercept.com/2025/03/03/gop-trump-donors-pittsburgh-mayor-ed-gainey/\n",
      "- From:   The Intercept (2025-03-03 14:49)\n",
      "Fundus-Article including 1 image(s):\n",
      "- Title: \"Millie Bobby Brown Calls Out Media for Criticizing Her Appearance\"\n",
      "- Text:  \"\"I grew up in front of the world, and for some reason, people can’t seem to grow\n",
      "          with me,\" the Stranger Things actress said  Millie Bobby Brown [...]\"\n",
      "- URL:    https://www.rollingstone.com/tv-movies/tv-movie-news/millie-bobby-brown-appearance-media-response-1235287392/\n",
      "- From:   Rolling Stone (2025-03-04 09:47)\n"
     ]
    }
   ],
   "source": [
    "# initialize the crawler for news publishers based in the US\n",
    "crawler = Crawler(PublisherCollection.us)\n",
    "\n",
    "# crawl 2 articles and print\n",
    "for article in crawler.crawl(max_articles=2):\n",
    "    print(article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Millie Bobby Brown Calls Out Media for Criticizing Her Appearance\n",
      "en\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\"I grew up in front of the world, and for some reason, people can’t seem to grow with me,\" the Stranger Things actress said\\n\\nMillie Bobby Brown responded to ongoing criticism of her appearance. In an emotional Instagram post, the actress said she wanted to “take a moment to address something that I think is bigger than just me, something that affects every young woman who grows up under public scrutiny.”\\n\\n“I started in this industry when I was 10 years old,” she said. “I grew up in front of the world, and for some reason, people can’t seem to grow with me. Instead, they act like I’m supposed to stay frozen in time, like I should still look the way I did on Stranger Things Season 1. And because I don’t, I’m now a target.”\\n\\nBrown shared several headlines that have rudely critiqued her grown-up, blonde look. They included “What has Millie Bobby Brown done to her face?” and “Why are Gen Zers like Millie Bobby Brown ageing so badly?”\\n\\n“This isn’t journalism,” Brown responded. “This is bullying. The fact that adult writers are spending their time dissecting my face, my body, my choices, it’s disturbing. The fact that some of these articles are written by women? Even worse. We always talk about supporting and uplifting young women, but when the time comes, it seems easier to tear them down for clicks. Disillusioned people can’t handle seeing a girl become a woman on her terms, not theirs.”\\n\\nShe continued, “I refuse to apologize for growing up. I refuse to make myself smaller to fit the unrealistic expectations of people who can’t handle seeing a girl become a woman. I will not be shamed for how I look, how I dress, or how I present myself. We have become a society where it’s so much easier to criticize than it is to pay a compliment. Why is the knee-jerk reaction to say something horrible rather than to say something nice? If you have a problem with that, I have to wonder—what is it that actually makes you so uncomfortable? Let’s do better. Not just for me, but for every young girl who deserves to grow up without fear of being torn apart for simply existing.” Editor’s picks The 100 Best TV Episodes of All Time The 250 Greatest Albums of the 21st Century So Far The 500 Greatest Albums of All Time The 200 Greatest Singers of All Time\\n\\nSeveral actors responded to the post, including Sarah Jessica Parker, who commented, “Enormously proud of you.” Matthew Modine, Brown’s co-star on Stranger Things, added, “Yes. Good for you! Brava.”\\n\\nSharon Stone replied, “Beautifully said Thx it really doesn’t matter our age or stature, we must be willing to own ourselves fully not fall to the false ideology of tear down media. Good job my friend.”\\n\\nAaron Paul noted, “You are such a beautiful example of grace and mutuality. Way to stand up for yourself. So proud of you Mills.”\\n\\nMckenna Grace, another young star who has been critiqued for her red carpet appearances, wrote, “No young woman or person deserves to feel pressure or cruelty for simply existing. You are so well spoken and so beautiful. Very well said, thank you for making this video.”\\n\\nBrown has been making the rounds on red carpets to promote her new film Electric State, which also stars Chris Pratt. In December, the actress wrapped the fifth and final season of Stranger Things, sharing a video of her emotional farewell speech. “I am nowhere near ready to leave you guys,” Brown told the cast and crew. “I love each and every one of you and I’ll forever carry the memories and bonds we’ve created together as a family.”'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(article.title)\n",
    "print(article.lang) # detects language of article\n",
    "article.plaintext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fundus-Article including 1 image(s):\n",
      "- Title: \"David Johansen’s Debauched, Preening Brilliance\"\n",
      "- Text:  \"As the frontman of the New York Dolls, Johansen was instrumental in the genesis\n",
      "          of punk in the nineteen-seventies. His solo work was equally [...]\"\n",
      "- URL:    https://www.newyorker.com/news/postscript/david-johansens-debauched-preening-brilliance\n",
      "- From:   The New Yorker (2025-03-04 06:00)\n",
      "Fundus-Article including 1 image(s):\n",
      "- Title: \"The Show That Finds the Intrigue Lurking in the Everyday\"\n",
      "- Text:  \"“The Curious History of Your Home” delves into the origins of the humdrum.\n",
      "          Society has changed in monumental ways, the British historian [...]\"\n",
      "- URL:    https://www.newyorker.com/magazine/podcast-dept/the-origins-of-the-humdrum-curious-history-of-your-home-podcast\n",
      "- From:   The New Yorker (2025-03-04 06:00)\n"
     ]
    }
   ],
   "source": [
    "# initialize the crawler for The New Yorker\n",
    "crawler = Crawler(PublisherCollection.us.TheNewYorker)\n",
    "\n",
    "# crawl 2 articles and print\n",
    "for article in crawler.crawl(max_articles=2):\n",
    "    print(article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawl_headlines(crawlers, name_of_publishers, article_number=20):\n",
    "    \"\"\"Crawls headlines from a list of crawlers for specified publishers.\n",
    "\n",
    "    This function takes three arguments:\n",
    "        - crawlers: A list of web crawlers, each responsible for a specific publisher.\n",
    "        - name_of_publishers: A list of publisher names corresponding to the crawlers.\n",
    "        - article_number (optional): The maximum number of articles to crawl per publisher. Defaults to 20.\n",
    "\n",
    "    It returns a dictionary where the keys are publisher names and the values are lists of headlines crawled from those publishers.\n",
    "    \"\"\"\n",
    "\n",
    "    headlines = {}\n",
    "\n",
    "    for crawler, name_of_publisher in zip(crawlers, name_of_publishers):\n",
    "        \"\"\"Iterates through crawlers and corresponding publisher names.\"\"\"\n",
    "\n",
    "        publisher = []\n",
    "\n",
    "        for article in tqdm(crawler.crawl(max_articles=article_number)):\n",
    "            \"\"\"Crawls the title of articles from the current crawler up to the specified article_number.\"\"\"\n",
    "            publisher.append(article.title)\n",
    "\n",
    "        headlines[name_of_publisher] = publisher\n",
    "\n",
    "    return headlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:18,  1.84s/it]\n",
      "10it [00:19,  1.99s/it]\n"
     ]
    }
   ],
   "source": [
    "crawler1 = Crawler(PublisherCollection.us.CNBC)\n",
    "crawler2 = Crawler(PublisherCollection.us.TheNation)\n",
    "\n",
    "crawlers = [crawler1, crawler2]\n",
    "names_of_publishers = [\"CNBC\", \"The Nation\"]\n",
    "headlines = crawl_headlines(crawlers, names_of_publishers, article_number=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CNBC': [\"Bitcoin erases all of its gain that followed Trump's crypto reserve announcement\",\n",
       "  \"Best Buy CEO warns price increases are 'highly likely' after Trump tariffs\",\n",
       "  'Why automakers including Honda and Toyota are pouring millions into rockets and satellites',\n",
       "  '5 things to know before the stock market opens Tuesday',\n",
       "  \"Tesla's worst month since 2022 coincided with Elon Musk's first full month in White House\",\n",
       "  \"Trump's Mexico tariffs could raise produce prices in the next few days, Target CEO says\",\n",
       "  'Waymo, Uber begin offering robotaxi rides in Austin ahead of SXSW',\n",
       "  \"Pro-Trump techies enraged by president's crypto reserve announcement, causing early rift\",\n",
       "  \"Smartphone startup Nothing tries to stir market out of 'sea of sameness' with $400 phone\",\n",
       "  'As the U.S. halts military aid to Kyiv, how long can Ukraine continue to fight Russia?'],\n",
       " 'The Nation': ['Ro Khanna Is Doing More Than Voting “No”',\n",
       "  'The Democrats Should Boycott Trump’s Speech to Congress This Week',\n",
       "  'Art Spiegelman and the Inescapable Shadow of Fascism',\n",
       "  'Long Live the…',\n",
       "  'Nusrat Fateh Ali Khan’s Voice From the Past',\n",
       "  'Disgraced Former Governor Andrew Cuomo Is Running for Mayor',\n",
       "  'When Russia Massacred Ukrainian Prisoners of War',\n",
       "  'How Do We Combat the Racist History of Public Education?',\n",
       "  'MSNBC’s Death Rattle',\n",
       "  'The Most Disgraceful Foreign Policy Spectacle in US History']}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_labels(publisher_headlines):\n",
    "    \"\"\"Predicts sentiment labels for headlines from each publisher.\n",
    "\n",
    "    This function takes a dictionary `publisher_headlines` as input. \n",
    "    The dictionary keys are publisher names and the values are lists of headlines.\n",
    "\n",
    "    The function performs sentiment analysis on each headline and stores the predicted labels \n",
    "    in a new dictionary with the same publisher names as keys.\n",
    "\n",
    "    It returns a dictionary where the keys are publisher names and the values are lists of predicted sentiment labels \n",
    "    for the corresponding headlines.\n",
    "    \"\"\"\n",
    "\n",
    "    sentiments_per_publisher = {}\n",
    "\n",
    "    # Load a sentiment classifier (TextClassifier likely refers to a custom class or library)\n",
    "    tagger = TextClassifier.load('sentiment')  \n",
    "\n",
    "    for key, values in publisher_headlines.items():\n",
    "        \"\"\"Iterates through each publisher and its corresponding headlines.\"\"\"\n",
    "\n",
    "        temp = []\n",
    "        for value in values:\n",
    "            \"\"\"Iterates through each headline for the current publisher\"\"\"\n",
    "            sentence = Sentence(value)  # Create a Sentence object (likely custom class) for the headline\n",
    "            tagger.predict(sentence)    # Predict sentiment label for the sentence using the loaded classifier\n",
    "            temp.append(sentence.get_label().value)  # Append the predicted label value to a temporary list\n",
    "\n",
    "        sentiments_per_publisher[key] = temp  # Add the list of predicted labels for the publisher to the result dictionary\n",
    "\n",
    "    return sentiments_per_publisher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-04 08:36:48,870 https://nlp.informatik.hu-berlin.de/resources/models/sentiment-curated-distilbert/sentiment-en-mix-distillbert_4.pt not found in cache, downloading to /var/folders/_d/c5j2kkcx3jvfgg9tymcv58yr0000gn/T/tmpgt9z95pb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 253M/253M [00:15<00:00, 17.6MB/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-04 08:37:04,255 copying /var/folders/_d/c5j2kkcx3jvfgg9tymcv58yr0000gn/T/tmpgt9z95pb to cache at /Users/samauyeung/.flair/models/sentiment-en-mix-distillbert_4.pt\n",
      "2025-03-04 08:37:04,308 removing temp file /var/folders/_d/c5j2kkcx3jvfgg9tymcv58yr0000gn/T/tmpgt9z95pb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ceb4977f0334368a60a1e783776e903",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d38f277bec43435f9f11e37daf8aed45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e304bd2027c44f7eacd768b364f2d107",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f866db14f5e4fe69fa33d605ff2c154",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sentiments_per_publisher=predict_labels(headlines) # getting sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_statistics(sentiments_per_publisher, number_of_articles=20):\n",
    "    \"\"\"\n",
    "    This function iterates over a dictionary of sentiments per publisher and prints statistics about the sentiment distribution.\n",
    "\n",
    "    Args:\n",
    "        sentiments_per_publisher (dict): A dictionary where keys are publishers and values are lists of sentiment labels for their articles.\n",
    "        number_of_articles (int, optional): The number of articles to consider when calculating statistics. Defaults to 20.\n",
    "    \"\"\"\n",
    "\n",
    "    for keys, values in sentiments_per_publisher.items():\n",
    "        \"\"\"\n",
    "        Iterates over each publisher and their corresponding sentiment labels.\n",
    "        \"\"\"\n",
    "\n",
    "        positive = 0\n",
    "        negative = 0\n",
    "        something_else = 0\n",
    "        for value in values:\n",
    "            \"\"\"\n",
    "            Iterates over each sentiment label for the current publisher.\n",
    "            \"\"\"\n",
    "\n",
    "            if value == \"POSITIVE\":\n",
    "                positive += 1\n",
    "            elif value == \"NEGATIVE\":\n",
    "                negative += 1\n",
    "            else:\n",
    "                something_else += 1\n",
    "        print(f\"{keys} has {positive} positive and {negative} negative headlines out of {number_of_articles}.\")\n",
    "        if something_else >= 1:\n",
    "            print(f\"If something got wrong then it has {something_else} something_else headlines.\")\n",
    "        print()\n",
    "\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNBC has 2 positive and 8 negative headlines out of 10.\n",
      "\n",
      "The Nation has 2 positive and 8 negative headlines out of 10.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_statistics(sentiments_per_publisher,number_of_articles = len(sentiments_per_publisher['CNBC']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ro Khanna Is Doing More Than Voting “No”',\n",
       " 'The Democrats Should Boycott Trump’s Speech to Congress This Week',\n",
       " 'Art Spiegelman and the Inescapable Shadow of Fascism',\n",
       " 'Long Live the…',\n",
       " 'Nusrat Fateh Ali Khan’s Voice From the Past',\n",
       " 'Disgraced Former Governor Andrew Cuomo Is Running for Mayor',\n",
       " 'When Russia Massacred Ukrainian Prisoners of War',\n",
       " 'How Do We Combat the Racist History of Public Education?',\n",
       " 'MSNBC’s Death Rattle',\n",
       " 'The Most Disgraceful Foreign Policy Spectacle in US History']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Yep, many of these titles sound negative to me; though Trump's bombastic bullying of Ukraine President Zelensky really was disgraceful\n",
    "headlines['The Nation']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to filter by topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Any\n",
    "\n",
    "keywords = ['market','stock']\n",
    "def body_filter(extracted: Dict[str, Any]) -> bool:\n",
    "    if body := extracted.get(\"body\"):\n",
    "        for word in keywords:\n",
    "            if word in str(body).casefold():\n",
    "                return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fundus-Article including 3 image(s):\n",
      "- Title: \"Latin America’s New Right Ushers in Pan-American Trumpism\"\n",
      "- Text:  \"Donald Trump is a wild card in Latin America. Who will he galvanize more? His\n",
      "          natural allies, including leaders who share many of his culture- [...]\"\n",
      "- URL:    https://theintercept.com/2025/03/02/trump-latin-america-new-right/\n",
      "- From:   The Intercept (2025-03-02 18:49)\n",
      "Fundus-Article including 1 image(s):\n",
      "- Title: \"Hotel management platform Mews books $75M round led by Tiger Global\"\n",
      "- Text:  \"Despite clouds of uncertainty looming over the economy and geopolitics, people\n",
      "          still want to travel. To meet that demand, Mews, an Amsterdam- [...]\"\n",
      "- URL:    https://techcrunch.com/2025/03/04/hotel-management-platform-mews-books-75m-round-led-by-tiger-global/\n",
      "- From:   TechCrunch (2025-03-04 12:16)\n"
     ]
    }
   ],
   "source": [
    "crawler = Crawler(PublisherCollection.us)\n",
    "\n",
    "for us_themed_article in crawler.crawl(max_articles=2,only_complete=body_filter):\n",
    "    print(us_themed_article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "def date_filter(extracted: Dict[str, Any]) -> bool:\n",
    "    start_date = datetime.date(2024,11,1)\n",
    "    end_date = datetime.date(2024,12,1)\n",
    "    if publishing_date := extracted.get(\"publishing_date\"):\n",
    "        return not (start_date <= publishing_date.date() <= end_date)\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fundus-Article:\n",
      "- Title: \"Peacock Promo Codes and Coupons\"\n",
      "- Text:  \"Watch your favorite TV shows for less this month and save on a subscription with\n",
      "          the latest Peacock coupons from WIRED.  Named after NBC’s iconic [...]\"\n",
      "- URL:    https://www.wired.com/story/peacock-promo-code/\n",
      "- From:   Wired (2024-11-28 02:00)\n",
      "Fundus-Article:\n",
      "- Title: \"Visible Promo Code: Save $10 Per Month in March 2025\"\n",
      "- Text:  \"Find great deals and promo codes for Visible at WIRED and save big, whether\n",
      "          you're a long-time customer or a newbie.  Visible offers access [...]\"\n",
      "- URL:    https://www.wired.com/story/visible-promo-code/\n",
      "- From:   Wired (2024-11-23 02:20)\n"
     ]
    }
   ],
   "source": [
    "for us_themed_article in crawler.crawl(max_articles=2,only_complete=date_filter):\n",
    "    print(us_themed_article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erdos_spring_2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
