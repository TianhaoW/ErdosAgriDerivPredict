{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "70385994-1458-465a-8fba-f775db94de21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in 1.csv: Index(['COOPID', 'YEAR', 'MONTH', 'DAY', 'precipitation'], dtype='object')\n",
      "Columns in 2.csv: Index(['COOPID', 'YEAR', 'MONTH', 'DAY', 'precipitation'], dtype='object')\n",
      "Columns in 3.csv: Index(['COOPID', 'YEAR', 'MONTH', 'DAY', 'precipitation'], dtype='object')\n",
      "Columns in 4.csv: Index(['COOPID', 'YEAR', 'MONTH', 'DAY', 'precipitation'], dtype='object')\n",
      "Columns in 5.csv: Index(['COOPID', 'YEAR', 'MONTH', 'DAY', 'precipitation'], dtype='object')\n",
      "Columns in 6.csv: Index(['COOPID', 'YEAR', 'MONTH', 'DAY', 'precipitation'], dtype='object')\n",
      "Columns in 7.csv: Index(['COOPID', 'YEAR', 'MONTH', 'DAY', 'precipitation'], dtype='object')\n",
      "Columns in 8.csv: Index(['COOPID', 'YEAR', 'MONTH', 'DAY', 'precipitation'], dtype='object')\n",
      "Columns in 9.csv: Index(['COOPID', 'YEAR', 'MONTH', 'DAY', 'precipitation'], dtype='object')\n",
      "Columns in 10.csv: Index(['COOPID', 'YEAR', 'MONTH', 'DAY', 'precipitation'], dtype='object')\n",
      "Columns in 11.csv: Index(['COOPID', 'YEAR', 'MONTH', 'DAY', 'precipitation'], dtype='object')\n",
      "Columns in 12.csv: Index(['COOPID', 'YEAR', 'MONTH', 'DAY', 'precipitation'], dtype='object')\n",
      "Columns in 13.csv: Index(['COOPID', 'YEAR', 'MONTH', 'DAY', 'precipitation'], dtype='object')\n",
      "Columns in 14.csv: Index(['COOPID', 'YEAR', 'MONTH', 'DAY', 'precipitation'], dtype='object')\n",
      "Columns in 15.csv: Index(['COOPID', 'YEAR', 'MONTH', 'DAY', 'precipitation'], dtype='object')\n",
      "Columns in 16.csv: Index(['COOPID', 'YEAR', 'MONTH', 'DAY', 'precipitation'], dtype='object')\n",
      "Columns in 17.csv: Index(['COOPID', 'YEAR', 'MONTH', 'DAY', 'precipitation'], dtype='object')\n",
      "Columns in 18.csv: Index(['COOPID', 'YEAR', 'MONTH', 'DAY', 'precipitation'], dtype='object')\n",
      "Columns in 19.csv: Index(['COOPID', 'YEAR', 'MONTH', 'DAY', 'precipitation'], dtype='object')\n",
      "Columns in 20.csv: Index(['COOPID', 'YEAR', 'MONTH', 'DAY', 'precipitation'], dtype='object')\n",
      "         DATE  PRECIPITATION\n",
      "0  2002-01-02         0.2945\n",
      "1  2002-01-03         0.2010\n",
      "2  2002-01-04         0.0000\n",
      "3  2002-01-06         0.1130\n",
      "4  2002-01-07         0.0340\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Initialize an empty list to store the precipitation data\n",
    "precipitation_data = []\n",
    "\n",
    "# Initialize a list for the date columns (Year, Month, Day)\n",
    "dates = []\n",
    "\n",
    "# Loop through each file (from 1.csv to 20.csv)\n",
    "for i in range(1, 21):\n",
    "    # Read the CSV file\n",
    "    filename = f'{i}.csv'\n",
    "    df = pd.read_csv(filename)\n",
    "\n",
    "    # Clean column names by stripping any extra spaces\n",
    "    df.columns = df.columns.str.strip()\n",
    "\n",
    "    # Debugging: Print column names to check for correct 'precipitation' column\n",
    "    print(f\"Columns in {filename}: {df.columns}\")\n",
    "    \n",
    "    # Filter out rows where precipitation is -99.99 (invalid data)\n",
    "    valid_precipitation = df[df['precipitation'] != -99.99]\n",
    "    \n",
    "    # Collect the date information\n",
    "    if i == 1:\n",
    "        # Capture the dates only once\n",
    "        dates = valid_precipitation[['YEAR', 'MONTH', 'DAY']]\n",
    "\n",
    "    # Add the valid precipitation data to the list for further processing\n",
    "    if len(precipitation_data) == 0:\n",
    "        precipitation_data = valid_precipitation[['YEAR', 'MONTH', 'DAY', 'precipitation']].copy()\n",
    "    else:\n",
    "        # Merge the data with the existing list of valid data\n",
    "        precipitation_data = pd.merge(precipitation_data, valid_precipitation[['YEAR', 'MONTH', 'DAY', 'precipitation']],\n",
    "                                      on=['YEAR', 'MONTH', 'DAY'], how='inner', suffixes=('', f'_from_{i}'))\n",
    "\n",
    "# Ensure we only have valid precipitation values (non -99.99) and merge on the common dates\n",
    "# Calculate the average precipitation across all files for each date, by taking the mean\n",
    "precipitation_data['PRECIPITATION'] = precipitation_data[[col for col in precipitation_data.columns if 'precipitation' in col]].mean(axis=1)\n",
    "\n",
    "# Create a new column 'DATE' in 'YYYY-MM-DD' format\n",
    "precipitation_data['DATE'] = precipitation_data.apply(lambda row: f\"{int(row['YEAR'])}-{int(row['MONTH']):02d}-{int(row['DAY']):02d}\", axis=1)\n",
    "\n",
    "# Keep only the 'DATE' and 'PRECIPITATION' columns\n",
    "final_data = precipitation_data[['DATE', 'PRECIPITATION']]\n",
    "\n",
    "# Export the DataFrame to a new CSV file\n",
    "final_data.to_csv('combined_precipitation_data.csv', index=False)\n",
    "\n",
    "# Display the combined data preview\n",
    "print(final_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f7c741b-b145-40cd-92b7-e25bae5961a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        DATE  LOSS AREA\n",
      "0 2002-12-31     100000\n",
      "1 2003-12-31     200000\n",
      "2 2004-12-31     300000\n",
      "3 2005-12-31     400000\n",
      "4 2006-12-31     500000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anshuman Bhardwaj\\AppData\\Local\\Temp\\ipykernel_28284\\3254318101.py:4: FutureWarning: 'A' is deprecated and will be removed in a future version, please use 'YE' instead.\n",
      "  dates = pd.date_range(start=\"2002-01-01\", end=\"2024-12-31\", freq=\"A\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a list of dates from 2002 to 2024\n",
    "dates = pd.date_range(start=\"2002-01-01\", end=\"2024-12-31\", freq=\"A\")\n",
    "\n",
    "# Create the LOSS AREA values (100000, 200000, ..., 2300000)\n",
    "loss_area_values = [100000 * (i + 1) for i in range(len(dates))]\n",
    "\n",
    "# Create a DataFrame\n",
    "data = pd.DataFrame({\n",
    "    'DATE': dates,\n",
    "    'LOSS AREA': loss_area_values\n",
    "})\n",
    "\n",
    "# Save to CSV\n",
    "data.to_csv('fake_loss_acreage.csv', index=False)\n",
    "\n",
    "# Show the first few rows of the DataFrame to verify\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97df907c-5fa9-4afb-88fa-d7330e97e7ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        DATE  LOSS AREA\n",
      "0 2002-01-01     100000\n",
      "1 2002-01-02     100000\n",
      "2 2002-01-03     100000\n",
      "3 2002-01-04     100000\n",
      "4 2002-01-05     100000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a list of all dates from January 1st, 2002 to December 31st, 2024\n",
    "dates = pd.date_range(start=\"2002-01-01\", end=\"2024-12-31\", freq=\"D\")\n",
    "\n",
    "# Create the LOSS AREA values (100000, 200000, ..., 2300000) following an arithmetic progression\n",
    "# We want the LOSS AREA to increase by 100000 each year\n",
    "loss_area_values = [100000 * ((date.year - 2002) + 1) for date in dates]\n",
    "\n",
    "# Create a DataFrame\n",
    "data = pd.DataFrame({\n",
    "    'DATE': dates,\n",
    "    'LOSS AREA': loss_area_values\n",
    "})\n",
    "\n",
    "# Save to CSV\n",
    "data.to_csv('fake_loss_acreage.csv', index=False)\n",
    "\n",
    "# Show the first few rows of the DataFrame to verify\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28e9768f-ea99-445e-87ec-8950c3e0c080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        DATE  PRECIPITATION  CLOSE PRICE  LOSS AREA\n",
      "0 2002-01-02         0.2945    92.949997     100000\n",
      "1 2002-01-03         0.2010    91.349998     100000\n",
      "2 2002-01-04         0.0000    94.250000     100000\n",
      "3 2002-01-07         0.0340    93.500000     100000\n",
      "4 2002-01-08         0.0010    93.500000     100000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the cleaned data (from the first file 'cleaned_data.csv')\n",
    "cleaned_data = pd.read_csv('cleaned_data.csv')\n",
    "\n",
    "# Load the fake loss acreage data (from the second file 'fake_loss_acreage.csv')\n",
    "loss_acreage_data = pd.read_csv('fake_loss_acreage.csv')\n",
    "\n",
    "# Convert 'DATE' columns to datetime format for both datasets\n",
    "cleaned_data['DATE'] = pd.to_datetime(cleaned_data['DATE'], format='%Y-%m-%d')\n",
    "loss_acreage_data['DATE'] = pd.to_datetime(loss_acreage_data['DATE'], format='%Y-%m-%d')\n",
    "\n",
    "# Merge the two datasets on the 'DATE' column\n",
    "merged_data = pd.merge(cleaned_data, loss_acreage_data, on='DATE', how='left')\n",
    "\n",
    "# Handle missing values by forward filling (recommended way)\n",
    "merged_data = merged_data.ffill()\n",
    "\n",
    "# Alternatively, if you want to drop rows with missing values (uncomment below)\n",
    "# merged_data = merged_data.dropna()\n",
    "\n",
    "# Save the combined dataset to a new CSV file\n",
    "merged_data.to_csv('combined_data.csv', index=False)\n",
    "\n",
    "# Show the first few rows of the combined data to verify\n",
    "print(merged_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ff4573-92d6-4827-96cd-60667d47c0b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
