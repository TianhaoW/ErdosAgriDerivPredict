{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import TimeSeriesSplit, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import xgboost as xgb\n",
    "import seaborn as sns\n",
    "\n",
    "from src.data.preprocess import extend_market_data"
   ],
   "id": "31207753cedc798c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Getting and preprocessing the data",
   "id": "6485f211906758b0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "SRW = yf.Ticker(\"ZW=F\")\n",
    "SRW_data = SRW.history(start =\"2014-01-01\").drop(['Dividends', 'Stock Splits'], axis=1)\n",
    "SRW_data = extend_market_data(SRW_data)\n",
    "SRW_data['Target'] = SRW_data['Log_Return'].shift(-1)\n",
    "SRW_data.dropna(inplace=True)\n",
    "SRW_data.head()"
   ],
   "id": "30f0a05922929e16"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Defining the feature columns and the train test split",
   "id": "df0fc4f103fdabdf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "feature_cols = ['Close', 'Volume', 'Day_Of_Year', 'Year', 'Month', 'Day' ,'DTE', '7D_Volatility', '14D_ATR', '7D_MA', '7D_EMA', '14D_RSI']\n",
    "splitting_point = '2025-01-01'\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_test_pd = SRW_data[SRW_data.index >= splitting_point][feature_cols]\n",
    "y_test = SRW_data[SRW_data.index >= splitting_point]['Target']\n",
    "X_train_pd = SRW_data[SRW_data.index < splitting_point][feature_cols]\n",
    "y_train = SRW_data[SRW_data.index < splitting_point]['Target']\n",
    "\n",
    "X_train = scaler.fit_transform(X_train_pd)\n",
    "X_test = scaler.transform(X_test_pd)"
   ],
   "id": "b21472bd641e9e4e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Linear regression model with CV",
   "id": "aa880807e2860af0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "model = LinearRegression()\n",
    "\n",
    "cv_scores = cross_val_score(model, X_train, y_train, cv=tscv, scoring='r2')\n",
    "print(f'Cross-validation R^2 scores on the training set: {cv_scores}')\n",
    "print(f'Average R^2 score: {np.mean(cv_scores):.4f}')\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(f\"The R^2 score on the testing set: {r2_score(y_test, y_pred):.4f}\")\n",
    "\n",
    "plt.figure(figsize=(16, 6))\n",
    "plt.title('The Linear Regression Model on the testing set')\n",
    "sns.lineplot(x=y_test.index, y=y_pred, label='prediction')\n",
    "sns.lineplot(x=y_test.index, y=y_test, label='actual')\n",
    "\n",
    "plt.figure(figsize=(16, 6))\n",
    "plt.title('The Linear Regression Model on the training set')\n",
    "sns.lineplot(x=y_train[2000:].index, y=model.predict(X_train[2000:]), label='prediction')\n",
    "sns.lineplot(x=y_train[2000:].index, y=y_train[2000:], label='actual', alpha = 0.5)"
   ],
   "id": "b5f8ebe6b73f2520"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Understanding the Feature Importance",
   "id": "472eec969e1c076f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "coefficients = model.coef_\n",
    "coefficients_df = pd.DataFrame({\"Feature\": feature_cols, \"Coefficient\": coefficients}).sort_values(by=\"Coefficient\", key=abs, ascending=False)\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.barh(coefficients_df['Feature'], coefficients_df['Coefficient'], color='skyblue')\n",
    "plt.xlabel('Coefficient Value')\n",
    "plt.ylabel('Feature')\n",
    "plt.title('Feature Importance in Linear Regression')\n",
    "plt.gca().invert_yaxis()  # Invert y-axis for better readability\n",
    "plt.show()"
   ],
   "id": "c239d58d7de372e8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "correlation_matrix = X_train_pd.merge(y_train, left_index=True, right_index=True).corr()\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt=\".2f\", cmap=\"coolwarm\", linewidths=0.5)\n",
    "plt.title(\"Feature Correlation Matrix\")\n",
    "plt.show()"
   ],
   "id": "687dd657877dedfe"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Lasso regression on the market data",
   "id": "d020af1689f5c7e8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "lasso_model = Lasso(alpha=0.0001)\n",
    "lasso_model.fit(X_train, y_train)\n",
    "\n",
    "cv_scores = cross_val_score(lasso_model, X_train, y_train, cv=tscv, scoring='r2')\n",
    "print(f'Cross-validation R^2 scores on the training set: {cv_scores}')\n",
    "print(f'Average R^2 score: {np.mean(cv_scores):.4f}')\n",
    "\n",
    "lasso_model.fit(X_train, y_train)\n",
    "y_pred = lasso_model.predict(X_test)\n",
    "print(f\"The Lasso Regression R^2 score on the testing set: {r2_score(y_test, y_pred):.4f}\")\n",
    "\n",
    "plt.figure(figsize=(16, 6))\n",
    "plt.title('The Linear Regression Model on the testing set')\n",
    "sns.lineplot(x=y_test.index, y=y_pred, label='prediction')\n",
    "sns.lineplot(x=y_test.index, y=y_test, label='actual')\n",
    "\n",
    "plt.figure(figsize=(16, 6))\n",
    "plt.title('The Lasso Regression Model on the training set')\n",
    "sns.lineplot(x=y_train[1000:].index, y=lasso_model.predict(X_train[1000:]), label='prediction')\n",
    "sns.lineplot(x=y_train[1000:].index, y=y_train[1000:], label='actual', alpha = 0.3)\n",
    "\n",
    "coefficients = lasso_model.coef_\n",
    "coefficients_df = pd.DataFrame({\"Feature\": feature_cols, \"Coefficient\": coefficients}).sort_values(by=\"Coefficient\", key=abs, ascending=False)\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.barh(coefficients_df['Feature'], coefficients_df['Coefficient'], color='skyblue')\n",
    "plt.xlabel('Coefficient Value')\n",
    "plt.ylabel('Feature')\n",
    "plt.title('Feature Importance in Linear Regression')\n",
    "plt.gca().invert_yaxis()  # Invert y-axis for better readability\n",
    "plt.show()"
   ],
   "id": "7c833be75180527b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Linear regression model on the training set without 2022 data",
   "id": "ea6ffe2b6e6e11b8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "X_train_new = X_train_pd[X_train_pd.index.year != 2022]\n",
    "y_train_new = y_train[X_train_pd.index.year != 2022]\n",
    "\n",
    "X_train_new = scaler.fit_transform(X_train_new)\n",
    "X_test = scaler.transform(X_test_pd)\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "model = LinearRegression()\n",
    "\n",
    "cv_scores = cross_val_score(model, X_train_new, y_train_new, cv=tscv, scoring='r2')\n",
    "print(f'Cross-validation R^2 scores on the training set: {cv_scores}')\n",
    "print(f'Average R^2 score: {np.mean(cv_scores):.4f}')\n",
    "\n",
    "model.fit(X_train_new, y_train_new)\n",
    "y_pred = model.predict(X_test)\n",
    "print(f\"The R^2 score on the testing set: {r2_score(y_test, y_pred):.4f}\")\n",
    "\n",
    "plt.figure(figsize=(16, 6))\n",
    "plt.title('The Linear Regression Model on the testing set')\n",
    "sns.lineplot(x=y_test.index, y=y_pred, label='prediction')\n",
    "sns.lineplot(x=y_test.index, y=y_test, label='actual')\n",
    "\n",
    "plt.figure(figsize=(16, 6))\n",
    "plt.title('The Linear Regression Model on the training set')\n",
    "sns.lineplot(x=y_train_new[1500:].index, y=model.predict(X_train_new[1500:]), label='prediction')\n",
    "sns.lineplot(x=y_train_new[1500:].index, y=y_train_new[1500:], label='actual', alpha = 0.3)\n"
   ],
   "id": "3b69442dd650646b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "coefficients = model.coef_\n",
    "coefficients_df = pd.DataFrame({\"Feature\": feature_cols, \"Coefficient\": coefficients}).sort_values(by=\"Coefficient\", key=abs, ascending=False)\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.barh(coefficients_df['Feature'], coefficients_df['Coefficient'], color='skyblue')\n",
    "plt.xlabel('Coefficient Value')\n",
    "plt.ylabel('Feature')\n",
    "plt.title('Feature Importance in Linear Regression')\n",
    "plt.gca().invert_yaxis()  # Invert y-axis for better readability\n",
    "plt.show()"
   ],
   "id": "e39ff8fe306a2f91"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# XGB Model with CV",
   "id": "99d4b6b49780418e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "tscv = TimeSeriesSplit(n_splits=10)\n",
    "xgb_model = xgb.XGBRegressor(\n",
    "    n_estimators=1000,\n",
    "    learning_rate=0.01,\n",
    "    max_depth=3,\n",
    "    eval_metric=r2_score,\n",
    "#    device='cuda',\n",
    "    reg_alpha=0.1,\n",
    "    reg_lambda=0.1,\n",
    "#    gamma=0.1,\n",
    "#    early_stopping_rounds=250,\n",
    "#    min_child_weight=5,\n",
    "#    subsample=0.7,\n",
    "#    colsample_bytree=0.7,\n",
    ")\n",
    "\n",
    "cv_scores = cross_val_score(xgb_model, X_train_new, y_train_new, cv=tscv, scoring='r2')\n",
    "print(f'Cross-validation R2 scores: {cv_scores}')  # Convert to positive MAE values\n",
    "print(f'Average R2: {np.mean(cv_scores):.4f}')"
   ],
   "id": "224a82a0c80f2bf2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "xgb_model.fit(X_train_new, y_train_new, verbose=50,eval_set=[(X_train_new, y_train_new), (X_test, y_test)])\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "\n",
    "plt.figure(figsize=(16, 6))\n",
    "plt.title('The XGBoost Model on the testing set')\n",
    "sns.lineplot(x=y_test.index, y=y_pred, label='prediction')\n",
    "sns.lineplot(x=y_test.index, y=y_test, label='actual', alpha = 0.3)\n",
    "\n",
    "plt.figure(figsize=(16, 6))\n",
    "plt.title('The XGBoost Model on the training set')\n",
    "sns.lineplot(x=y_train_new[2000:].index, y=xgb_model.predict(X_train_new[2000:]), label='prediction')\n",
    "sns.lineplot(x=y_train_new[2000:].index, y=y_train_new[2000:], label='actual', alpha = 0.3)\n",
    "\n"
   ],
   "id": "5ffa5ab1d9a003c8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# NN Model",
   "id": "e462c75eb4db24b5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.optim as optim"
   ],
   "id": "3cde8705f82de2c4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Converting the training set and testing set to the torch tensors\n",
    "X_train, y_train = torch.tensor(X_train_new, dtype=torch.float32), torch.tensor(y_train_new, dtype=torch.float32)\n",
    "X_test, y_test = torch.tensor(X_test, dtype=torch.float32), torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "# Create DataLoader class\n",
    "BATCH_SIZE = 32\n",
    "train_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(TensorDataset(X_test, y_test), batch_size=BATCH_SIZE, shuffle=False)"
   ],
   "id": "5053226a51f0e928"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(12, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.linear_relu_stack(x)\n",
    "        return output\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ],
   "id": "fea2e30bc0c824d4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
    "\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 10 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "#    test_loss /= num_batches\n",
    "    print(f\"Test loss: \\n: {test_loss:>0.8f} \\n\")"
   ],
   "id": "bc14f8342f15981f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "epochs = 500\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_loader, model, loss_fn, optimizer)\n",
    "    test(test_loader, model, loss_fn)\n",
    "print(\"Done!\")"
   ],
   "id": "3f3d22ecc1fdc969"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred_test = model(X_test).squeeze().numpy()\n",
    "\n",
    "y_pred_test_rescaled = y_pred_test.reshape(-1, 1)\n",
    "y_test_rescaled = y_test.numpy().reshape(-1, 1)\n",
    "\n",
    "# Plot results\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(y_pred_test_rescaled, label='Predicted')\n",
    "plt.plot(y_test_rescaled, label='Actual')\n",
    "plt.legend()\n",
    "plt.title(\"NN Model Predictions on testing set\")\n",
    "plt.show()\n",
    "\n",
    "print(r2_score(y_test_rescaled, y_pred_test_rescaled))"
   ],
   "id": "66b5820622f2b19e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred_train = model(X_train).squeeze().numpy()\n",
    "\n",
    "y_pred_train_rescaled = y_pred_train.reshape(-1, 1)\n",
    "y_train_rescaled = y_train.numpy().reshape(-1, 1)\n",
    "\n",
    "# Plot results\n",
    "\n",
    "plt.figure(figsize=(16, 10))\n",
    "plt.plot(y_train_rescaled[2000:], label='Predicted', alpha=0.7)\n",
    "plt.plot(y_pred_train_rescaled[2000:], label='Actual')\n",
    "plt.legend()\n",
    "plt.title(\"NN Model Predictions on Training set\")\n",
    "plt.show()\n",
    "\n",
    "print(r2_score(y_train_rescaled , y_pred_train_rescaled))"
   ],
   "id": "497fa4321e5dd984"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# LSTM Model",
   "id": "de2d81f4bbdaff90"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import MinMaxScaler\n"
   ],
   "id": "e1890bff25425be8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "# df['scaled_value'] = scaler.fit_transform(df[['value']])\n",
    "\n",
    "def create_sequences(data, seq_length):\n",
    "    sequences = []\n",
    "    targets = []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        sequences.append(data[i:i+seq_length])\n",
    "        targets.append(data[i+seq_length][-1])\n",
    "    return np.array(sequences), np.array(targets)\n",
    "\n",
    "data = SRW_data[feature_cols + ['Target']]\n",
    "\n",
    "SEQ_LENGTH = 60\n",
    "X, y = create_sequences(data.values, SEQ_LENGTH)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train, y_train = torch.tensor(X[:-500], dtype=torch.float32), torch.tensor(y[:-500], dtype=torch.float32)\n",
    "X_test, y_test = torch.tensor(X[-500:], dtype=torch.float32), torch.tensor(y[-500:], dtype=torch.float32)\n",
    "\n",
    "# Reshape for LSTM (batch_size, seq_length, num_features)\n",
    "X_train = X_train.view(-1, SEQ_LENGTH, 13)\n",
    "X_test = X_test.view(-1, SEQ_LENGTH, 13)\n",
    "\n",
    "# Create DataLoader\n",
    "BATCH_SIZE = 32\n",
    "train_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(TensorDataset(X_test, y_test), batch_size=BATCH_SIZE, shuffle=False)"
   ],
   "id": "38a6b8bb068df821"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_dim=13, hidden_dim=64, num_layers=2, output_dim=1):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        out = self.fc(lstm_out[:, -1, :])  # Take last output from LSTM\n",
    "        return out\n",
    "\n",
    "# Initialize Model\n",
    "model = LSTMModel()\n"
   ],
   "id": "8d271b3e83a63073"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Define Loss and Optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training Loop\n",
    "EPOCHS = 1000\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for batch_x, batch_y in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(batch_x)\n",
    "        loss = criterion(y_pred.squeeze(), batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{EPOCHS}], Loss: {epoch_loss/len(train_loader):.6f}')"
   ],
   "id": "b9ddfcdfe869d273"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred_test = model(X_test).squeeze().numpy()\n",
    "\n",
    "# Inverse transform predictions\n",
    "# y_pred_test_rescaled = scaler.inverse_transform(y_pred_test.reshape(-1, 1))\n",
    "# y_test_rescaled = scaler.inverse_transform(y_test.numpy().reshape(-1, 1))\n",
    "\n",
    "y_pred_test_rescaled = y_pred_test.reshape(-1, 1)\n",
    "y_test_rescaled = y_test.numpy().reshape(-1, 1)\n",
    "\n",
    "# Plot results\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(data.index[-500:], y_test_rescaled, label='Actual')\n",
    "plt.plot(data.index[-500:], y_pred_test_rescaled, label='Predicted')\n",
    "plt.legend()\n",
    "plt.title(\"LSTM Model Predictions on testing set\")\n",
    "plt.show()\n",
    "\n",
    "print(f\"r2 score {r2_score(y_test_rescaled, y_pred_test_rescaled):.4f}\")"
   ],
   "id": "6d48da179536ce15"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
